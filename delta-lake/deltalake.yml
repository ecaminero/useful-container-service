# Feel free to modify this file to suit your needs.
---
x-databricks-common:  &databricks-common
  image: bitnami/spark:latest

  environment: &databricks-common-env
    SPARK_RPC_AUTHENTICATION_ENABLED: "no"
    SPARK_RPC_ENCRYPTION_ENABLED: "no"
    SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
    SPARK_SSL_ENABLED: "no"

services:
  # spark-master:
  #   <<: *databricks-common
  #   container_name: spark-master
  #   ports:
  #     - "8080:8080"
  #     - "7077:7077"
  #   environment:
  #     <<: *databricks-common-env
  #     SPARK_MOD: "master"
  #   volumes:
  #     - spark-data:/opt/spark/data
  #     - ../delta-lake:/delta-lake

  # # Spark Worker Node
  # spark-worker:
  #   <<: *databricks-common
  #   container_name: spark-worker
  #   depends_on:
  #     - spark-master
  #   environment:
  #     <<: *databricks-common-env
  #     SPARK_MODE: "worker"
  #     SPARK_MASTER_URL: "spark://spark-master:7077"
  #     SPARK_WORKER_MEMORY: "200M"
  #     SPARK_WORKER_CORES: "0.5"
  #   volumes:
  #     - spark-data:/opt/spark/data
  #     - ../delta-lake:/delta-lake

  # Delta Sharing Server
  delta-lake:
    build:
      context: .
      dockerfile: ./Containerfile
    container_name: deltalake-server
    ports:
      - "8080:8080"
    environment:
      - DELTA_SHARING_SERVER_PORT=8080
      - DELTA_SHARING_SERVER_HOST=0.0.0.0
    volumes:
      - ./volumen/delta-sharing:/delta-sharing
    # command: ["--config", "./config/deltalake-server-config.yml"]

  # MinIO for object storage (optional but recommended)
  # minio:
  #   image: minio/minio
  #   container_name: minio
  #   ports:
  #     - "9000:9000"
  #     - "9001:9001"
  #   environment:
  #     - MINIO_ROOT_USER=minioadmin
  #     - MINIO_ROOT_PASSWORD=minioadmin
  #   volumes:
  #     - minio-data:/data
  #   command: server /data --console-address ":9001"

volumes:
  spark-data:
  minio-data:

networks:
  default:
    name: delta-network